{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b352fc53",
   "metadata": {},
   "source": [
    "# Intelligent LLM Data Conversation Demo\n",
    "\n",
    "This notebook demonstrates how to use the Big Data Migrator's LLM conversation system for data analysis tasks. The system combines a local LLM with data context understanding to provide intelligent insights and recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa55d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "# Import Big Data Migrator components\n",
    "from app.llm.conversation_system import LLMConversationSystem\n",
    "from app.llm.online_llm_fallback import OnlineLLMConfig\n",
    "from app.memory.memory_monitor import MemoryMonitor\n",
    "from app.memory.resource_optimizer import ResourceOptimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42885d1",
   "metadata": {},
   "source": [
    "## 1. Initialize the LLM Conversation System\n",
    "\n",
    "First, we need to initialize the LLM conversation system with appropriate configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa9ab8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv(os.path.join(\"../config\", \".env\"))\n",
    "\n",
    "# Initialize memory monitoring\n",
    "memory_monitor = MemoryMonitor()\n",
    "resource_optimizer = ResourceOptimizer(memory_monitor)\n",
    "\n",
    "# Configure online LLM fallback (optional)\n",
    "ENABLE_ONLINE_FALLBACK = os.getenv(\"ENABLE_ONLINE_FALLBACK\", \"false\").lower() == \"true\"\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "\n",
    "online_llm_config = None\n",
    "if ENABLE_ONLINE_FALLBACK and OPENAI_API_KEY:\n",
    "    online_llm_config = OnlineLLMConfig(\n",
    "        api_key=OPENAI_API_KEY,\n",
    "        model=os.getenv(\"ONLINE_LLM_MODEL\", \"gpt-4o\")\n",
    "    )\n",
    "\n",
    "# Initialize the conversation system\n",
    "llm_system = LLMConversationSystem(\n",
    "    local_llm_url=os.getenv(\"LOCAL_LLM_URL\", \"http://localhost:1234/v1\"),\n",
    "    local_llm_model=os.getenv(\"LOCAL_LLM_MODEL\", \"CodeLlama-34B-Instruct\"),\n",
    "    memory_monitor=memory_monitor,\n",
    "    resource_optimizer=resource_optimizer,\n",
    "    online_llm_config=online_llm_config,\n",
    "    enable_online_fallback=ENABLE_ONLINE_FALLBACK\n",
    ")\n",
    "\n",
    "# Check connection to the local LLM\n",
    "connection_status = llm_system.llm_client.check_connection()\n",
    "print(f\"Connection status: {connection_status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee8a734",
   "metadata": {},
   "source": [
    "## 2. Create Sample Data for Analysis\n",
    "\n",
    "Let's create some sample data to demonstrate the system capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea98cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample sales data\n",
    "np.random.seed(42)\n",
    "num_records = 1000\n",
    "\n",
    "# Generate sample data\n",
    "product_ids = np.random.randint(1, 21, size=num_records)\n",
    "customer_ids = np.random.randint(101, 251, size=num_records)\n",
    "quantities = np.random.randint(1, 10, size=num_records)\n",
    "unit_prices = np.random.uniform(10.0, 1000.0, size=num_records).round(2)\n",
    "order_dates = pd.date_range(start='2024-01-01', end='2024-05-01', periods=num_records)\n",
    "\n",
    "# Create sales dataframe\n",
    "sales_df = pd.DataFrame({\n",
    "    'order_id': range(1, num_records + 1),\n",
    "    'product_id': product_ids,\n",
    "    'customer_id': customer_ids,\n",
    "    'quantity': quantities,\n",
    "    'unit_price': unit_prices,\n",
    "    'order_date': order_dates,\n",
    "    'total_amount': quantities * unit_prices\n",
    "})\n",
    "\n",
    "# Create product dataframe\n",
    "product_categories = ['Electronics', 'Furniture', 'Clothing', 'Books', 'Food']\n",
    "product_df = pd.DataFrame({\n",
    "    'product_id': range(1, 21),\n",
    "    'product_name': [f'Product {i}' for i in range(1, 21)],\n",
    "    'category': np.random.choice(product_categories, size=20),\n",
    "    'supplier_id': np.random.randint(1, 6, size=20)\n",
    "})\n",
    "\n",
    "# Create customer dataframe\n",
    "customer_df = pd.DataFrame({\n",
    "    'customer_id': range(101, 251),\n",
    "    'customer_name': [f'Customer {i}' for i in range(101, 251)],\n",
    "    'city': np.random.choice(['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix'], size=150),\n",
    "    'segment': np.random.choice(['Consumer', 'Corporate', 'Home Office'], size=150)\n",
    "})\n",
    "\n",
    "# Save dataframes to CSV\n",
    "os.makedirs('sample_data', exist_ok=True)\n",
    "sales_df.to_csv('sample_data/sales.csv', index=False)\n",
    "product_df.to_csv('sample_data/products.csv', index=False)\n",
    "customer_df.to_csv('sample_data/customers.csv', index=False)\n",
    "\n",
    "print(f\"Created sample datasets with {len(sales_df)} sales records, {len(product_df)} products, and {len(customer_df)} customers\")\n",
    "print(\"Files saved in 'sample_data' directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049368b9",
   "metadata": {},
   "source": [
    "## 3. Create a Conversation with Data Context\n",
    "\n",
    "Now we'll create a conversation that includes our sample data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc836787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data file paths\n",
    "data_files = [\n",
    "    os.path.abspath('sample_data/sales.csv'),\n",
    "    os.path.abspath('sample_data/products.csv'),\n",
    "    os.path.abspath('sample_data/customers.csv')\n",
    "]\n",
    "\n",
    "# Create a conversation\n",
    "conversation_id = llm_system.create_conversation(\n",
    "    title=\"Sample Sales Data Analysis\",\n",
    "    data_files=data_files\n",
    ")\n",
    "\n",
    "print(f\"Created conversation with ID: {conversation_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a248346f",
   "metadata": {},
   "source": [
    "## 4. Ask Questions About the Data\n",
    "\n",
    "Let's ask some questions about our data and see the LLM's responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd1773d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask about top performing products\n",
    "response = llm_system.add_message(\n",
    "    message=\"What are the top 5 selling products by total revenue?\",\n",
    "    conversation_id=conversation_id\n",
    ")\n",
    "\n",
    "print(response[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2451dc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask about customer segments\n",
    "response = llm_system.add_message(\n",
    "    message=\"Which customer segment generates the most revenue? Break it down by city.\",\n",
    "    conversation_id=conversation_id\n",
    ")\n",
    "\n",
    "print(response[\"response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b366cb3",
   "metadata": {},
   "source": [
    "## 5. Get Intelligent Guidance\n",
    "\n",
    "The system can generate guidance based on the data and conversation context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbae9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate guidance\n",
    "guidance = llm_system.generate_guidance(conversation_id)\n",
    "\n",
    "# Display suggestions\n",
    "print(\"=== Suggested Questions ===\")\n",
    "for question in guidance.get(\"questions\", []):\n",
    "    print(f\"- {question['content']}\")\n",
    "\n",
    "print(\"\\n=== Data Exploration Suggestions ===\")\n",
    "for suggestion in guidance.get(\"suggestions\", []):\n",
    "    print(f\"- {suggestion['content']}\")\n",
    "\n",
    "print(\"\\n=== Improvement Recommendations ===\")\n",
    "for improvement in guidance.get(\"improvements\", []):\n",
    "    print(f\"- {improvement['content']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a6fdca",
   "metadata": {},
   "source": [
    "## 6. Data Validation and Relationship Detection\n",
    "\n",
    "Let's ask about data quality and relationships between our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073aedaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask about data quality\n",
    "response = llm_system.add_message(\n",
    "    message=\"Are there any data quality issues I should be aware of in these datasets?\",\n",
    "    conversation_id=conversation_id\n",
    ")\n",
    "\n",
    "print(response[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd44e0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask about relationships between datasets\n",
    "response = llm_system.add_message(\n",
    "    message=\"What are the relationships between these three datasets? How should I join them?\",\n",
    "    conversation_id=conversation_id\n",
    ")\n",
    "\n",
    "print(response[\"response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e84634b",
   "metadata": {},
   "source": [
    "## 7. Schema Optimization with Online LLM Fallback (Optional)\n",
    "\n",
    "If online LLM fallback is enabled, we can use it for complex schema optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c334df81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if online fallback is enabled\n",
    "if llm_system.enable_online_fallback:\n",
    "    # Run schema optimization\n",
    "    print(\"Starting schema optimization with online LLM...\")\n",
    "    schema_results = llm_system.optimize_schema_with_fallback(conversation_id)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\n=== Schema Optimization Results ===\")\n",
    "    \n",
    "    if \"optimized_schema\" in schema_results:\n",
    "        print(\"\\nOptimized Schema:\")\n",
    "        print(schema_results[\"optimized_schema\"])\n",
    "    \n",
    "    if \"recommendations\" in schema_results:\n",
    "        print(\"\\nRecommendations:\")\n",
    "        for rec in schema_results[\"recommendations\"]:\n",
    "            print(f\"- {rec}\")\n",
    "else:\n",
    "    print(\"Online LLM fallback is not enabled. To use schema optimization:\")\n",
    "    print(\"1. Set ENABLE_ONLINE_FALLBACK=true in your .env file\")\n",
    "    print(\"2. Set a valid OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6cccb2",
   "metadata": {},
   "source": [
    "## 8. Generate SQL Queries\n",
    "\n",
    "The LLM can also help generate SQL queries for data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50710262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask for a SQL query\n",
    "response = llm_system.add_message(\n",
    "    message=\"Could you generate a SQL query to find the top 3 products by revenue for each city?\",\n",
    "    conversation_id=conversation_id\n",
    ")\n",
    "\n",
    "print(response[\"response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9b7a1c",
   "metadata": {},
   "source": [
    "## 9. Review Conversation History\n",
    "\n",
    "Finally, let's retrieve and display the conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676749cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get conversation details\n",
    "conversation = llm_system.conversation_manager.get_conversation(conversation_id)\n",
    "\n",
    "print(f\"Conversation Title: {conversation.title}\")\n",
    "print(f\"Created at: {pd.to_datetime(conversation.created_at, unit='s')}\")\n",
    "print(f\"Updated at: {pd.to_datetime(conversation.updated_at, unit='s')}\")\n",
    "print(f\"Number of messages: {len(conversation.messages)}\")\n",
    "print(\"\\nData files:\")\n",
    "for file in conversation.data_files:\n",
    "    print(f\"- {file}\")\n",
    "\n",
    "print(\"\\nConversation Summary:\")\n",
    "if conversation.context_summary:\n",
    "    print(conversation.context_summary)\n",
    "else:\n",
    "    print(\"No summary available\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
